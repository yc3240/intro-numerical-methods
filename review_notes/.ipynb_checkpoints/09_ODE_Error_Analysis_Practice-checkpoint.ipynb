{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%precision 16\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence\n",
    "\n",
    "Suppose\n",
    "\n",
    "$t_f$ = the time that we want to evaluate $u(t_n)$\n",
    "\n",
    "$N$ = number of samples, or number of time steps needed to reach the final time of interest $t_f$ \n",
    "\n",
    "$\\Delta t$ = sampling time\n",
    "\n",
    "Then $~~ N \\Delta t = t_f ~~ \\Rightarrow ~~ N = \\frac{t_f}{\\Delta t}$\n",
    "\n",
    "A method is convergent if this sequence converges to the true solution at the same time\n",
    "$$\n",
    "    \\lim_{N\\rightarrow \\infty} U^N = u(t_f).\n",
    "$$\n",
    "\n",
    "or \n",
    "\n",
    "$$\n",
    "    \\lim_{\\Delta t\\rightarrow 0} U(t_f) = u(t_f).\n",
    "$$\n",
    "\n",
    "where $u(t_f)$ is the true solution.\n",
    "\n",
    "In order to be convergent, a method have to be\n",
    "\n",
    " - **consistent** which as before meant that the local truncation error $T = \\mathcal{O}(\\Delta t^p)$ where $p > 0$,\n",
    " - **zero-stable** which implies that the sum total of the errors as $\\Delta t \\rightarrow 0$ is bounded and has the same order as $T$ which we know goes to zero as $\\Delta t \\rightarrow 0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency\n",
    "\n",
    "A method is called *consistent* if \"local\" truncation error\n",
    "\n",
    "$$\n",
    "\\lim_{\\Delta t \\rightarrow 0} T(t, u; \\Delta t) = 0.\n",
    "$$\n",
    "\n",
    "**Definition 1:** We define the *truncation error* of a scheme by\n",
    "\n",
    "$$T(t, u; \\Delta t) = \\frac{1}{\\Delta t} [U_{n+1} - u(t + \\Delta t)]$$\n",
    "\n",
    "**Definition 2:** We say that a method is *order* $p$ accurate if\n",
    "\n",
    "$$||T(t, u; \\Delta t) || \\leq C \\Delta t^p$$\n",
    "\n",
    "uniformally on $t \\in [0, T]$.  This can also be written as $T(t, u; \\Delta t) = \\mathcal{O}(\\Delta t^p)$.  Note that a method is consistent if $p > 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Examples **\n",
    "\n",
    "1. Forward Euler Method\n",
    "\n",
    "2. Leap-Frog Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Forward Euler Method\n",
    "\n",
    "Forward Euler Method gives a scheme\n",
    "\n",
    "$$\n",
    "U_{n+1} = u(t_n) + \\Delta t f(t_n)\n",
    "$$\n",
    "\n",
    "and therefore\n",
    "$$\\begin{aligned}\n",
    "    T(t, u; \\Delta t) &= \\frac{1}{\\Delta t} [U_{n+1} - u(t + \\Delta t)] \\\\\n",
    "    &= \\frac{1}{\\Delta t} \\left[ \\underbrace{u_n + \\Delta t f(t_n, u_n)}_{U_{n+1}} - \\underbrace{\\left( u_n + \\Delta t f(t_n, u_n) + \\frac{u''(t_n)}{2} \\Delta t^2 + \\mathcal{O}(\\Delta t^3) \\right )}_{\\text{Taylor Series expansion of } u(t + \\Delta t)}\\right ] \\\\\n",
    "    &= \\frac{1}{\\Delta t} \\left[ - \\frac{u''(t_n)}{2} \\Delta t^2 - \\mathcal{O}(\\Delta t^3) \\right ] \\\\\n",
    "    &= - \\frac{u''(t_n)}{2} \\Delta t - \\mathcal{O}(\\Delta t^2)\n",
    "\\end{aligned}$$\n",
    "\n",
    "Forward Euler Method is first order accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Leap-Frog Method\n",
    "\n",
    "Recall that leap-frog has the form\n",
    "$$\n",
    "    \\frac{U_{n+1} - U_{n-1}}{2 \\Delta t} = f(t_n, U_n)\n",
    "$$\n",
    "or\n",
    "$$\n",
    "    U_{n+1} = U_{n-1} + 2 \\Delta t f(t_n, U_n).\n",
    "$$\n",
    "\n",
    "Compute truncation error\n",
    "\n",
    "$$\\begin{aligned}\n",
    "T(t, u; \\Delta t) &= \\frac{1}{\\Delta t} [U_{n+1} - u(t + \\Delta t)] \\\\\n",
    "&= \\frac{1}{\\Delta t} \\left [\\underbrace{( U_{n-1} + 2 \\Delta t f(t_n, U_n)}_{\\text{Definition of Leap-Frog}} - \\underbrace{(u(t_n) + (t - t_n) u'(t_n) + (t - t_n)^2 \\frac{u''(t_n)}{2}  + (t - t_n)^3 \\frac{u'''(t_n)}{6} + \\mathcal{O}((t-t_n)^4)}_{\\text{Taylor Series Expansion of }U_{n+1} ~ - ~ u(t + \\Delta t)} \\right] \\\\\n",
    "&= \\frac{1}{\\Delta t} \\left [\\underbrace{\\left(u_n - \\Delta t f_n + \\Delta t^2 \\frac{u''(t_n)}{2}  - \\Delta t^3 \\frac{u'''(t_n)}{6} + \\mathcal{O}(\\Delta t^4)\\right)}_{\\text{T.S. of } U(t-\\Delta t)} + 2 \\Delta t f(t_n, U_n) - (u(t_n) + (t - t_n) u'(t_n) + (t - t_n)^2 \\frac{u''(t_n)}{2}  + (t - t_n)^3 \\frac{u'''(t_n)}{6} + \\mathcal{O}((t-t_n)^4) \\right]\n",
    "&=\\frac{1}{\\Delta t} \\left [- \\Delta t^3 \\frac{u'''(t_n)}{3} + \\mathcal{O}(\\Delta t^4) \\right ] \\\\\n",
    "&=- \\Delta t^2 \\frac{u'''(t_n)}{3} + \\mathcal{O}(\\Delta t^3)\n",
    "\\end{aligned}$$\n",
    "\n",
    "Leap-Frog method is second orer accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute Stability\n",
    "\n",
    "Zero stability is evaluated at $\\Delta t \\rightarrow 0$. Practically speaking, $\\Delta t \\rightarrow 0$ is very difficult to compute. \n",
    "\n",
    "Instead we often consider a finite $\\Delta t$ and examine if the method is stable for this particular choice of $\\Delta t$.  This has the practical upside that it will also tell us what particular $\\Delta t$ will ensure that our method is indeed stable.\n",
    "\n",
    "Before we solve a stability problem, there are several tricks that make the stability problem easier to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Stability Regions for Linear Multistep Methods\n",
    "\n",
    "Going back to linear multistep methods and applying them in general to our test problem we have\n",
    "\n",
    "$$\\sum^r_{j=0} \\alpha_j U_{n+j} = \\Delta t \\sum^r_{j=0} \\beta_j \\lambda U_{n+j}$$\n",
    "\n",
    "which can be written as \n",
    "\n",
    "$$\\sum^r_{j=0} (\\alpha_j - \\beta_j \\Delta t \\lambda) U_{n+j} = 0$$\n",
    "\n",
    "or using our notation of $z = \\Delta t \\lambda$ we have\n",
    "\n",
    "$$\\sum^r_{j=0} (\\alpha_j - \\beta_j z) U_{n+j} = 0.$$\n",
    "\n",
    "This has a similar form to the linear difference equations considered above!  Letting\n",
    "\n",
    "$$\\rho(\\xi) = \\sum^r_{j=0} \\alpha_j \\xi^j$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\\sigma(\\xi) = \\sum^r_{j=0} \\beta_j \\xi^j$$\n",
    "\n",
    "we can write the expression above as\n",
    "\n",
    "$$\\pi(\\xi, z) = \\rho(\\xi) - z \\sigma(\\xi)$$\n",
    "\n",
    "called the **stability polynomial** of the the linear multi-step method.  It turns out that if the roots $\\xi_i$ of this polynomial satisfy\n",
    "\n",
    "$$|\\xi_i| \\leq 1$$\n",
    "\n",
    "then the multi-step method is zero-stable.  We then define the region of absolute stability as the values for $z$ for which this is true.  This approach can also be applied to one-step methods.\n",
    "\n",
    "There are two methods to evaluate absolute stability:\n",
    "\n",
    "1. Analytical Solution\n",
    "\n",
    "2. Graphical Solotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analytical Solution\n",
    "\n",
    "**Step 1** List the method and rearrange to the form of\n",
    "$$\\sum^r_{j=0} \\alpha_j U_{n+j} = \\Delta t \\sum^r_{j=0} \\beta_j \\lambda U_{n+j}$$\n",
    "\n",
    "**Step 2** Introduce $z = 1 - \\Delta t \\lambda ~$ and $~U_n = \\xi^n ~$, then find the stability polynomial\n",
    "\n",
    "**Step 3** \n",
    "\n",
    "If relation between $\\xi ~$ and $z$ is simple (for example: Taylor Series Method and Euler's Method), then solve $\\pi(\\xi, z) = 0$ for $\\xi = g(z)$.\n",
    "\n",
    "**Step 4**\n",
    "\n",
    "Stability condition: $$\\big | \\xi \\big | \\leq 1 \\Rightarrow \\big | g(z) \\big | \\leq1$$\n",
    "\n",
    "By this constrain can we draw the region of stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphical Solution\n",
    "\n",
    "**Step 1** List the method and rearrange to the form of\n",
    "$$\\sum^r_{j=0} \\alpha_j U_{n+j} = \\Delta t \\sum^r_{j=0} \\beta_j \\lambda U_{n+j}$$\n",
    "\n",
    "**Step 2** Introduce $z = 1 - \\Delta t \\lambda ~$ and $~U_n = \\xi^n ~$, then find the stability polynomial\n",
    "\n",
    "**Step 3** \n",
    "\n",
    "If relation between $\\xi ~$ and $z$ is complicated (multi-step methods), let complex number $\\xi = |~\\xi~|~e^{j\\theta}$\n",
    "\n",
    "Stability condition gives $|~\\xi~| = 1$, so $\\xi = e^{j\\theta}$ represents the boundary of stability region.\n",
    "\n",
    "**Step 4**\n",
    "\n",
    "Plug in $\\xi = e^{j\\theta}$ into equation in step 2.\n",
    "\n",
    "$$\\pi(\\xi, z) = \\rho(\\xi) - z \\sigma(\\xi)$$\n",
    "\n",
    "Because stability condition $\\pi(\\xi, z) = 0$\n",
    "\n",
    "so $$z(\\xi) = \\frac{\\rho(\\xi)}{\\sigma(\\xi)}$$\n",
    "\n",
    "We can see z as a mapping function from $\\xi$ to complex $z$ plane."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
